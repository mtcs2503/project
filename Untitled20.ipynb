{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgEu8aPJgs97",
        "outputId": "0d83bf9e-4ae0-4b93-f9a0-6f8fc8cfeddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Simple 5-Gram Language Model ===\n",
            "\n",
            "Loading training text...\n",
            "Building 5-gram model...\n",
            "Total words: 130343\n",
            "Unique 5-gram contexts: 126880\n",
            "\n",
            "Model Examples:\n",
            "--------------------------------------------------\n",
            "\n",
            "Seed: 'it is a truth'\n",
            "Generated: It is a truth universally acknowledged, that a single. man in possession of a good fortune must. be in want of a wife. however little. known the feelings or.\n",
            "\n",
            "Seed: 'he was a man'\n",
            "Generated: He was a man in the early eighteenth century,. of course, could push this taste further than. a lady in the early nineteenth; and.\n",
            "\n",
            "Seed: 'she could not help'\n",
            "Generated: She could not help asking him whether he intended. to accept mr. bingleys invitation, and if he. did, whether he would think it proper to. join in the evenings.\n",
            "\n",
            "==================================================\n",
            "What the model learned (sample 5-grams):\n",
            "==================================================\n",
            "\n",
            "Context 1: the project gutenberg ebook\n",
            "  Can be followed by: of, pride, pride\n",
            "\n",
            "Context 2: project gutenberg ebook of\n",
            "  Can be followed by: pride\n",
            "\n",
            "Context 3: gutenberg ebook of pride\n",
            "  Can be followed by: and\n",
            "\n",
            "Context 4: ebook of pride and\n",
            "  Can be followed by: prejudice\n",
            "\n",
            "Context 5: of pride and prejudice\n",
            "  Can be followed by: this\n",
            "\n",
            "Context 6: pride and prejudice this\n",
            "  Can be followed by: ebook\n",
            "\n",
            "Context 7: and prejudice this ebook\n",
            "  Can be followed by: is\n",
            "\n",
            "Context 8: prejudice this ebook is\n",
            "  Can be followed by: for\n",
            "\n",
            "Context 9: this ebook is for\n",
            "  Can be followed by: the, the\n",
            "\n",
            "Context 10: ebook is for the\n",
            "  Can be followed by: use, use\n",
            "\n",
            "==================================================\n",
            "Testing specific predictions:\n",
            "==================================================\n",
            "\n",
            "After 'it is a truth', the model predicts:\n",
            "  universally\n",
            "\n",
            "Context 'he was a man' not found in model\n",
            "\n",
            "After 'she could not help', the model predicts:\n",
            "  asking, frequently, crying, saying,, fancying\n",
            "\n",
            "==================================================\n",
            "Longer generated example:\n",
            "==================================================\n",
            "\n",
            "In a country town 256 his parting obeisance 261. dawson 263 the elevation of his feelings 267. they had forgotten to leave any message 270. how nicely we are crammed in! 272 heading. to chapter xl. 278 I am determined never. to speak of it again 283 when colonel. millers regiment went away 285.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "# Fetch books from Project Gutenberg\n",
        "def get_book_text():\n",
        "    # Use Pride and Prejudice as example\n",
        "    url = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        text = response.text\n",
        "\n",
        "        # Extract main content\n",
        "        start = text.find(\"Chapter 1\")\n",
        "        end = text.find(\"End of the Project Gutenberg\")\n",
        "\n",
        "        if start != -1 and end != -1:\n",
        "            text = text[start:end]\n",
        "\n",
        "        # Clean the text\n",
        "        text = re.sub(r'[^\\w\\s.,;!?\\']', '', text)  # Keep basic punctuation\n",
        "        text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "        return text.lower()  # Convert to lowercase\n",
        "\n",
        "    except:\n",
        "        # Fallback text if fetch fails\n",
        "        return \"\"\"it is a truth universally acknowledged that a single man in\n",
        "        possession of a good fortune must be in want of a wife however little\n",
        "        known the feelings or views of such a man may be on his first entering\n",
        "        a neighbourhood this truth is so well fixed in the minds of the\n",
        "        surrounding families that he is considered as the rightful property of\n",
        "        some one or other of their daughters my dear mr bennet said his lady\n",
        "        to him one day have you heard that netherfield park is let at last\n",
        "        mr bennet replied that he had not but it is returned she for mrs long\n",
        "        has just been here and she told me all about it mr bennet made no\n",
        "        answer do not you want to know who has taken it cried his wife\n",
        "        impatiently you want to tell me and i have no objection to hearing it\n",
        "        this was invitation enough\"\"\"\n",
        "\n",
        "# Build 5-gram model\n",
        "def build_5gram_model(text):\n",
        "    words = text.split()\n",
        "\n",
        "    # Create 5-grams\n",
        "    ngrams = defaultdict(list)\n",
        "\n",
        "    # For each position, create context (4 words) -> next word\n",
        "    for i in range(len(words) - 4):\n",
        "        context = tuple(words[i:i+4])  # First 4 words\n",
        "        next_word = words[i+4]         # 5th word\n",
        "\n",
        "        # Store that this word can follow this context\n",
        "        ngrams[context].append(next_word)\n",
        "\n",
        "    print(f\"Total words: {len(words)}\")\n",
        "    print(f\"Unique 5-gram contexts: {len(ngrams)}\")\n",
        "\n",
        "    return ngrams\n",
        "\n",
        "# Generate text using 5-grams\n",
        "def generate_text(model, start_words, length=30):\n",
        "    # Convert starting words to list\n",
        "    current = start_words.lower().split()\n",
        "\n",
        "    # Ensure we have at least 4 words for context\n",
        "    while len(current) < 4:\n",
        "        # Find any context that starts with our words\n",
        "        for context in model.keys():\n",
        "            if context[0] == current[-1] if current else True:\n",
        "                # Add words from this context\n",
        "                for word in context:\n",
        "                    if word not in current:\n",
        "                        current.append(word)\n",
        "                        if len(current) >= 4:\n",
        "                            break\n",
        "                break\n",
        "\n",
        "    # Take last 4 words as current context\n",
        "    current_context = tuple(current[-4:])\n",
        "\n",
        "    # Generate words\n",
        "    for _ in range(length):\n",
        "        # Check if we know what comes after this context\n",
        "        if current_context in model and model[current_context]:\n",
        "            # Pick a random word that can follow this context\n",
        "            next_word = model[current_context][0]  # Use first one for simplicity\n",
        "\n",
        "            # In a better version, you'd pick based on frequency\n",
        "            # next_word = random.choice(model[current_context])\n",
        "\n",
        "            current.append(next_word)\n",
        "            # Update context: remove first word, add new word\n",
        "            current_context = tuple(current[-4:])\n",
        "        else:\n",
        "            # If we don't know this context, try shorter context\n",
        "            # Use last 3 words as new context\n",
        "            shorter_context = tuple(current[-3:])\n",
        "\n",
        "            # Look for contexts that end with our shorter context\n",
        "            possible_next = []\n",
        "            for context in model.keys():\n",
        "                if context[1:] == shorter_context and len(context) == 4:\n",
        "                    possible_next.extend(model[context])\n",
        "\n",
        "            if possible_next:\n",
        "                next_word = possible_next[0]\n",
        "                current.append(next_word)\n",
        "                current_context = tuple(current[-4:])\n",
        "            else:\n",
        "                # If still no match, use last word as context\n",
        "                last_word = current[-1]\n",
        "                # Find any context starting with this word\n",
        "                for context in model.keys():\n",
        "                    if context[0] == last_word:\n",
        "                        # Add the next word from this context\n",
        "                        current.append(context[1])\n",
        "                        current_context = tuple(current[-4:])\n",
        "                        break\n",
        "                else:\n",
        "                    # If nothing works, add a common word\n",
        "                    current.append(\"the\")\n",
        "                    current_context = tuple(current[-4:])\n",
        "\n",
        "    # Join words back into text\n",
        "    result = \" \".join(current)\n",
        "\n",
        "    # Basic capitalization\n",
        "    result = result.capitalize()\n",
        "    result = re.sub(r' i ', ' I ', result)\n",
        "    result = re.sub(r' mr ', ' Mr. ', result)\n",
        "    result = re.sub(r' mrs ', ' Mrs. ', result)\n",
        "\n",
        "    # Add periods\n",
        "    sentences = result.split()\n",
        "    for i in range(len(sentences)):\n",
        "        if i > 0 and i % 8 == 0 and i < len(sentences) - 1:\n",
        "            sentences[i] = sentences[i] + \".\"\n",
        "\n",
        "    return \" \".join(sentences) + \".\"\n",
        "\n",
        "# Main program\n",
        "print(\"=== Simple 5-Gram Language Model ===\\n\")\n",
        "\n",
        "# Get training text\n",
        "print(\"Loading training text...\")\n",
        "text = get_book_text()\n",
        "\n",
        "# Build model\n",
        "print(\"Building 5-gram model...\")\n",
        "model = build_5gram_model(text)\n",
        "\n",
        "# Show some examples\n",
        "print(\"\\nModel Examples:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Example 1\n",
        "seed1 = \"it is a truth\"\n",
        "print(f\"\\nSeed: '{seed1}'\")\n",
        "generated1 = generate_text(model, seed1, 25)\n",
        "print(f\"Generated: {generated1}\")\n",
        "\n",
        "# Example 2\n",
        "seed2 = \"he was a man\"\n",
        "print(f\"\\nSeed: '{seed2}'\")\n",
        "generated2 = generate_text(model, seed2, 20)\n",
        "print(f\"Generated: {generated2}\")\n",
        "\n",
        "# Example 3\n",
        "seed3 = \"she could not help\"\n",
        "print(f\"\\nSeed: '{seed3}'\")\n",
        "generated3 = generate_text(model, seed3, 25)\n",
        "print(f\"Generated: {generated3}\")\n",
        "\n",
        "# Show what the model learned\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"What the model learned (sample 5-grams):\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Show first 10 contexts and what follows\n",
        "sample_contexts = list(model.keys())[:10]\n",
        "for i, context in enumerate(sample_contexts):\n",
        "    words = list(context)\n",
        "    next_words = model[context][:3]  # Show first 3 possible next words\n",
        "\n",
        "    print(f\"\\nContext {i+1}: {' '.join(words)}\")\n",
        "    print(f\"  Can be followed by: {', '.join(next_words)}\")\n",
        "\n",
        "# Test with some specific contexts\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Testing specific predictions:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "test_contexts = [\n",
        "    (\"it\", \"is\", \"a\", \"truth\"),\n",
        "    (\"he\", \"was\", \"a\", \"man\"),\n",
        "    (\"she\", \"could\", \"not\", \"help\")\n",
        "]\n",
        "\n",
        "for context in test_contexts:\n",
        "    if context in model:\n",
        "        predictions = model[context][:5]  # Get first 5 predictions\n",
        "        print(f\"\\nAfter '{' '.join(context)}', the model predicts:\")\n",
        "        print(f\"  {', '.join(predictions)}\")\n",
        "    else:\n",
        "        print(f\"\\nContext '{' '.join(context)}' not found in model\")\n",
        "\n",
        "# Generate a longer example\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"Longer generated example:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "long_example = generate_text(model, \"in a country town\", 50)\n",
        "print(f\"\\n{long_example}\")"
      ]
    }
  ]
}